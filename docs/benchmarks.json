[
  {
    "description": "Community-driven evaluation based on human preference",
    "id": "lmsys",
    "last_updated": "2025-04-20",
    "name": "lmsys Chatbot Arena",
    "source_url": "https://beta.lmarena.ai/leaderboard/text",
    "type": "human_pref"
  },
  {
    "description": "Polyglot benchmark testing LLMs on 225 Exercism coding exercises across C++, Go, Java, JavaScript, Python, and Rust",
    "id": "aider_llm_bench",
    "last_updated": "2025-04-20",
    "name": "Aider LLM Benchmark",
    "source_url": "https://aider.chat/docs/leaderboards/",
    "type": "code_edit"
  },
  {
    "description": "Multiple-choice benchmark where individuals with high school knowledge outperform SOTA models",
    "id": "simple_bench",
    "last_updated": "2025-04-20",
    "name": "SimpleBench",
    "source_url": "https://simple-bench.com/",
    "type": "reasoning"
  },
  {
    "description": "A benchmark for LLMs designed with test set contamination and objective evaluation in mind",
    "id": "livebench",
    "last_updated": "2025-04-20",
    "name": "LiveBench",
    "source_url": "https://livebench.ai/#/",
    "type": "reasoning"
  }
]